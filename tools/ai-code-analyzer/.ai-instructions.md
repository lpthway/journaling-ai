# 🤖 AI Development Instructions - AI Code Analyzer Project

**CRITICAL**: Read this file EVERY TIME before working on this project!

## 📋 Essential First Steps (Every Session)

1. **ALWAYS CHECK PROGRESS FIRST**
   ```bash
   cat progress-tracker.md
   cat project-todo.md
   ```

2. **UPDATE SESSION INFO**
   - Add current date/time to progress tracker
   - Note what you're planning to work on
   - Review last session's outcomes

3. **CHECK DEVELOPMENT STANDARDS**
   - Review coding standards below
   - Check current Python/tech stack versions
   - Verify test coverage requirements

## 🎯 Project Context & Vision

**Goal**: Create a modular, reusable AI-powered code analysis framework that can intelligently analyze any codebase using multiple LLMs with advanced quota management and resume capabilities.

**Current State**: Project initialization phase
**Next Milestone**: Core framework architecture completion

## 🏗️ Architecture Principles

### **Modularity First**
- Each component should be independently testable
- Clear interfaces between modules
- Plugin-based architecture for analyzers
- Configuration-driven behavior

### **Technology Stack (Latest & Best)**

**Core Framework:**
- Python 3.11+ (latest stable with performance improvements)
- Pydantic v2.x (data validation and settings)
- Click 8.x (modern CLI framework)
- Rich 13.x (beautiful terminal UI)
- Typer (if Click becomes limiting)

**Configuration & Data:**
- YAML/TOML for configs (human-readable)
- SQLite with async support (simple, reliable)
- Pydantic for configuration validation
- Pathlib for all path operations

**Testing & Quality:**
- pytest with async support
- pytest-cov for coverage (aim for >90%)
- black + isort + ruff (modern Python linting)
- mypy for type checking
- pre-commit hooks

**Advanced Features:**
- asyncio for concurrent operations
- aiofiles for async file operations
- httpx for async HTTP requests
- structlog for structured logging

## 📝 Development Standards

### **Code Organization**
```python
# Every module should have:
"""Module docstring with purpose and usage examples."""

from __future__ import annotations  # Enable modern type hints

import logging
from pathlib import Path
from typing import Any, Optional

# Use structured logging
logger = logging.getLogger(__name__)

class ExampleClass:
    """Clear class docstring with examples."""
    
    def __init__(self, config: Config) -> None:
        """Initialize with type hints."""
        self._config = config
    
    async def process(self, data: str) -> dict[str, Any]:
        """Async by default for I/O operations."""
        logger.info("Processing data", extra={"data_length": len(data)})
        return {"result": "processed"}
```

### **Error Handling**
```python
# Custom exceptions for clarity
class AnalysisError(Exception):
    """Base exception for analysis errors."""
    pass

class QuotaExhaustedError(AnalysisError):
    """Raised when LLM quota is exhausted."""
    pass

# Comprehensive error context
try:
    result = await analyzer.analyze()
except QuotaExhaustedError as e:
    logger.error("Quota exhausted", extra={
        "provider": e.provider,
        "reset_time": e.reset_time,
        "session_id": session.id
    })
    await session.save_resume_point()
    raise
```

### **Configuration Management**
```python
# Use Pydantic for all configuration
from pydantic import BaseSettings, Field

class AnalyzerConfig(BaseSettings):
    """Configuration for AI analyzers."""
    
    max_tokens: int = Field(default=4000, description="Max tokens per request")
    timeout_seconds: int = Field(default=300, description="Request timeout")
    retry_attempts: int = Field(default=3, description="Max retry attempts")
    
    class Config:
        env_prefix = "AI_ANALYZER_"
        env_file = ".env"
```

## 📊 Progress Tracking Protocol

### **After Every Coding Session:**

1. **Update Progress Tracker**
   ```markdown
   ### Session YYYY-MM-DD HH:MM
   **Worked on**: [Component/Feature]
   **Completed**: [What was finished]
   **Challenges**: [Problems encountered]
   **Next**: [What to do next]
   **Files changed**: [List of modified files]
   ```

2. **Update TODO Status**
   ```markdown
   - [x] ~~Task completed~~
   - [ ] Task in progress (50% done - [specific status])
   - [ ] Task pending
   ```

3. **Document Decisions**
   ```markdown
   ### Technical Decisions
   - **Decision**: Chose asyncio over threading
   - **Reasoning**: Better for I/O heavy operations
   - **Impact**: All analyzers must be async
   - **Date**: 2025-08-07
   ```

4. **Update Architecture Documentation**
   - Keep architecture.md current
   - Document new interfaces
   - Update dependency diagrams

## 🧪 Testing Strategy

### **Test-Driven Development**
```python
# Write tests FIRST, then implementation
async def test_analyzer_handles_quota_exhaustion():
    """Test that analyzer properly handles quota limits."""
    analyzer = MockAnalyzer()
    analyzer.set_quota_exhausted(True)
    
    with pytest.raises(QuotaExhaustedError):
        await analyzer.analyze("test code")
    
    # Verify resume point was saved
    assert analyzer.session.resume_point is not None
```

### **Coverage Requirements**
- Minimum 90% test coverage
- All public APIs must have tests
- Integration tests for LLM interactions
- Mock external dependencies

## 🔄 Resume Protocol

### **When Resuming Work:**

1. **Environment Setup**
   ```bash
   cd /home/abrasko/Projects/journaling-ai/tools/ai-code-analyzer
   source venv/bin/activate  # If using venv
   python -m pytest  # Verify tests pass
   ```

2. **Context Recovery**
   - Read last session notes
   - Check git status and recent commits
   - Review current branch and pending PRs
   - Verify development environment

3. **Goal Alignment**
   - Confirm current milestone
   - Check if priorities have changed
   - Update task estimates if needed

## 🚀 Quality Gates

### **Before Each Commit:**
```bash
# Run quality checks
black .
isort .
ruff check .
mypy .
pytest --cov=src --cov-report=term-missing
```

### **Before Milestone Completion:**
- All tests passing
- Documentation updated
- API documentation current
- Integration tests verified
- Performance benchmarks run

## 📁 File Organization Reminder

```
/tools/ai-code-analyzer/
├── .ai-instructions.md        # THIS FILE - READ FIRST
├── progress-tracker.md        # Session notes and progress
├── project-todo.md           # Detailed TODO list
├── architecture.md           # Technical architecture docs
├── README.md                 # User-facing documentation
├── pyproject.toml           # Modern Python project config
├── src/ai_analyzer/         # Main source code
├── tests/                   # Test suite
├── docs/                    # Additional documentation
├── config/                  # Configuration templates
└── examples/                # Usage examples
```

## 🎯 Success Metrics

**Phase 1**: Core framework working with basic analysis
**Phase 2**: Multi-LLM support with intelligent failover
**Phase 3**: Advanced features and web UI
**Final**: Production-ready tool used by other developers

## ⚠️ Critical Reminders

1. **ALWAYS document WHY, not just WHAT**
2. **Type hints are mandatory**
3. **Async by default for I/O operations**
4. **Configuration over hardcoding**
5. **Test before implement**
6. **Update progress after every session**
7. **Use structured logging everywhere**
8. **Handle errors gracefully with context**

---

**Last Updated**: 2025-08-07  
**Current Milestone**: Phase 1 - Core Framework  
**Next Session Goal**: Create project structure and basic CLI
